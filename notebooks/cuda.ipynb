{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is there a gpu available? Yes\n",
      "Device Name: NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "Memory allocated in bytes: 0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Is there a gpu available? {'Yes' if torch.cuda.is_available() else 'No'}\")\n",
    "\n",
    "print(f\"Device Name: {torch.cuda.get_device_name(torch.cuda.current_device())}\")\n",
    "\n",
    "print(f\"Memory allocated in bytes: {torch.cuda.memory_allocated()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([1,23]).cuda()\n",
    "a.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "\n",
    "    def __init__(self, in_features = 4, h1=8, h2=9, out_features = 3):\n",
    "        super().__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(in_features,h1)\n",
    "        self.fc2 = nn.Linear(h1,h2)\n",
    "        self.fc3 = nn.Linear(h2,out_features)\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = F.relu(self.fc1(X))\n",
    "        X = F.relu(self.fc2(X))\n",
    "        X = self.fc3(X)\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(32)\n",
    "model = Model()\n",
    "gpumodel = model.cuda()\n",
    "\n",
    "next(gpumodel.parameters()).is_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(model.parameters()).is_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "0                5.1               3.5                1.4               0.2\n",
       "1                4.9               3.0                1.4               0.2\n",
       "2                4.7               3.2                1.3               0.2\n",
       "3                4.6               3.1                1.5               0.2\n",
       "4                5.0               3.6                1.4               0.2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_iris()\n",
    "X = pd.DataFrame(data['data'], columns=data['feature_names'])\n",
    "y = pd.Series(data['target'])\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape\n",
      "X_train: (120, 4)\n",
      "X_test: (30, 4)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X.values,y.values, test_size=0.2, random_state=33)\n",
    "print(f\"Shape\")\n",
    "print(f\"X_train: {X_train.shape}\")\n",
    "print(f\"X_test: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.FloatTensor(X_train).cuda()\n",
    "X_test = torch.FloatTensor(X_test).cuda()\n",
    "y_train = torch.FloatTensor(y_train).cuda().long()\n",
    "y_test = torch.FloatTensor(y_test).cuda().long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 2, 2], device='cuda:0')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Batches: 2\n",
      "Size of each batch: 60\n",
      "\n",
      "Number of Batches: 1\n",
      "Size of each batch: 60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def loader_info(loader: DataLoader) -> None:\n",
    "    print(f\"Number of Batches: {len(loader)}\")\n",
    "    print(f\"Size of each batch: {loader.batch_size}\\n\")\n",
    "\n",
    "trainloader = DataLoader(X_train, batch_size=60, shuffle=True, pin_memory=True)\n",
    "testloader = DataLoader(X_test, batch_size=60, shuffle=False, pin_memory=True)\n",
    "\n",
    "loader_info(trainloader)\n",
    "loader_info(testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | loss: 1.1507450342178345\n",
      "Epoch 10 | loss: 0.9371446371078491\n",
      "Epoch 20 | loss: 0.779624342918396\n",
      "Epoch 30 | loss: 0.6078532338142395\n",
      "Epoch 40 | loss: 0.39894530177116394\n",
      "Epoch 50 | loss: 0.2524919807910919\n",
      "Epoch 60 | loss: 0.14927688241004944\n",
      "Epoch 70 | loss: 0.10029558837413788\n",
      "Epoch 80 | loss: 0.08100691437721252\n",
      "Epoch 90 | loss: 0.07216038554906845\n",
      "Duration: 0.0030820250511169435 mins\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "epochs = 100\n",
    "losses = []\n",
    "\n",
    "for i in range(epochs):\n",
    "\n",
    "    y_pred = gpumodel(X_train)\n",
    "    loss = criterion(y_pred, y_train)\n",
    "    losses.append(loss.item())\n",
    "\n",
    "    if i%10 == 0:\n",
    "        print(f\"Epoch {i} | loss: {loss.item()}\")\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "total = time.time() - start\n",
    "print(f\"Duration: {total/60} mins\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1. tensor([-2.1234,  4.8067, -0.8803], device='cuda:0') 1\n",
      " 2. tensor([-1.7920,  5.3100, -1.5693], device='cuda:0') 1\n",
      " 3. tensor([  6.3723,   0.8741, -10.0971], device='cuda:0') 0\n",
      " 4. tensor([-3.9129,  4.5951,  1.1509], device='cuda:0') 1\n",
      " 5. tensor([-7.4882,  3.1953,  5.7839], device='cuda:0') 2\n",
      " 6. tensor([-10.5202,   1.6381,   9.6291], device='cuda:0') 2\n",
      " 7. tensor([  6.3364,   1.0237, -10.1951], device='cuda:0') 0\n",
      " 8. tensor([  7.0690,   0.7370, -10.9620], device='cuda:0') 0\n",
      " 9. tensor([-7.2218,  3.3422,  5.3528], device='cuda:0') 2\n",
      "10. tensor([-9.4170,  2.5675,  8.1028], device='cuda:0') 2\n",
      "11. tensor([-9.9029,  2.3388,  8.7141], device='cuda:0') 2\n",
      "12. tensor([ 6.2942,  0.6938, -9.8046], device='cuda:0') 0\n",
      "13. tensor([-9.3335,  2.1817,  8.1917], device='cuda:0') 2\n",
      "14. tensor([-3.7832,  4.5046,  1.0603], device='cuda:0') 1\n",
      "15. tensor([-7.8793,  3.0060,  6.2225], device='cuda:0') 2\n",
      "16. tensor([-1.8810,  5.1571, -1.3572], device='cuda:0') 1\n",
      "17. tensor([-5.7107,  3.5003,  3.6612], device='cuda:0') 2\n",
      "18. tensor([  7.2014,   0.7687, -11.1842], device='cuda:0') 0\n",
      "19. tensor([-3.2961,  4.7939,  0.3307], device='cuda:0') 1\n",
      "20. tensor([-7.7822,  3.7560,  5.7040], device='cuda:0') 2\n",
      "21. tensor([  6.6703,   0.8191, -10.4707], device='cuda:0') 0\n",
      "22. tensor([  7.4580,   0.9259, -11.7103], device='cuda:0') 0\n",
      "23. tensor([-9.7801,  2.1658,  8.6656], device='cuda:0') 2\n",
      "24. tensor([  6.5976,   0.7715, -10.3186], device='cuda:0') 0\n",
      "25. tensor([-7.4280,  2.8654,  5.9396], device='cuda:0') 2\n",
      "26. tensor([-6.1649,  3.3994,  4.2207], device='cuda:0') 2\n",
      "27. tensor([-3.1644,  4.7467,  0.2535], device='cuda:0') 1\n",
      "28. tensor([-1.5378,  4.9042, -1.5792], device='cuda:0') 1\n",
      "29. tensor([-7.4479,  3.1046,  5.7293], device='cuda:0') 2\n",
      "30. tensor([-6.7186,  3.1143,  4.9560], device='cuda:0') 2\n",
      "\n",
      "30 out of 30 = 100.00% correct\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(X_test):\n",
    "        y_val = gpumodel.forward(data)\n",
    "        print(f\"{i+1:2}. {str(y_val):38} {y_test[i]}\")\n",
    "        if y_val.argmax().item() == y_test[i]:\n",
    "            correct+=1\n",
    "\n",
    "print(f\"\\n{correct} out of {len(y_test)} = {100*correct/len(y_test):.2f}% correct\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
